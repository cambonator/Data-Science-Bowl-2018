{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ac76a406-f2bd-4983-8aaa-9f35cc130bbf",
    "_uuid": "98dd4df3bde2484278a6bc3e76f4e2f3738fa917"
   },
   "source": [
    "Source: https://www.kaggle.com/ahassaine/pure-image-processing-lb-0-274/code \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries and Global Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "963e73bf-7e69-4a68-845f-e4a4202cfff2",
    "_uuid": "241c639d46630418b994f941241f75440a8f0f9e"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.util import img_as_bool, img_as_uint, img_as_ubyte\n",
    "from skimage.transform import resize\n",
    "#import skimage\n",
    "#import glob\n",
    "import random\n",
    "from random import randint #, shuffle\n",
    "\n",
    "from keras import regularizers\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Activation, Dense, \\\n",
    "    UpSampling2D, BatchNormalization, add, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\n",
    "from keras import backend as K\n",
    "from keras.losses import binary_crossentropy, sparse_categorical_crossentropy\n",
    "\n",
    "model_checkpoint_file='meshnet_v2.h5'\n",
    "\n",
    "# Root folders for test and training data\n",
    "train_root = \"./stage1_train\"\n",
    "test_root = \"./stage1_test\"\n",
    "\n",
    "# Size we resize all images to\n",
    "#image_size = (128,128)\n",
    "\n",
    "img_height = 128\n",
    "img_width = 128\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='skimage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4ae021eb-5807-47b6-9e7d-51735cdfb314",
    "_uuid": "1b7f0851ca37aafdf1e3cb813f90d7f5eb417f11"
   },
   "source": [
    "# Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Training Data Images \n",
    "train_dirs = os.listdir(train_root)\n",
    "train_filenames=[os.path.join(train_root,file_id) + \"/images/\"+file_id+\".png\" for file_id in train_dirs]\n",
    "# Convert to B&W inline\n",
    "#train_images=[cv2.cvtColor(cv2.imread(imagefile),cv2.COLOR_BGR2GRAY) for imagefile in train_filenames]\n",
    "train_images=[imread(imagefile,as_grey=True) for imagefile in train_filenames]\n",
    "\n",
    "# Use this instead if you want color images\n",
    "#train_images=[imread(imagefile) for imagefile in train_filenames]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Import Training Masks\n",
    "# this takes longer than the training images because we have to\n",
    "# combine a lot of mask files\n",
    "\n",
    "# This function creates a single combined mask image \n",
    "# when given a list of masks\n",
    "# Probably a computationally faster way to do this...\n",
    "def collapse_masks(mask_list):\n",
    "    for i, mask_file in enumerate(mask_list):        \n",
    "        if i != 0:\n",
    "            # combine mask with previous mask in list \n",
    "            mask = np.maximum(mask, imread(os.path.join(train_root,mask_file)))\n",
    "        else:\n",
    "            # read first mask in\n",
    "            mask = imread(os.path.join(train_root,mask_file))\n",
    "    \n",
    "    return img_as_ubyte(mask)\n",
    "\n",
    "# Import all the masks\n",
    "train_mask_dirs = [ os.path.join(path, 'masks') for path in os.listdir(train_root) ]\n",
    "train_mask_files = [ [os.path.join(dir,file) for file in os.listdir(os.path.join(train_root,dir)) ]  for dir in train_mask_dirs]\n",
    "\n",
    "#def collapse_masks(mask_list):\n",
    "#    for i, mask_file in enumerate(mask_list):\n",
    "#        print(i)\n",
    "#        print(mask_file)\n",
    "        \n",
    "#testing = [collapse_masks(mask_files) for mask_files in train_mask_files]\n",
    "\n",
    "# Divide output of each mask by 255 to make a 1/0 binary mask\n",
    "train_masks = [ collapse_masks(mask_files) for mask_files in train_mask_files ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def comp_viz_mask(img):\n",
    "    #green channel happends to produce slightly better results\n",
    "    #than the grayscale image and other channels\n",
    "   # img_gray=img_rgb[:,:,1]#cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY)\n",
    "    #morphological opening (size tuned on training data)\n",
    "    circle7=cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(7,7))\n",
    "    img_open=cv2.morphologyEx(img, cv2.MORPH_OPEN, circle7)\n",
    "    #Otsu thresholding\n",
    "    img_th=cv2.threshold(img_open,0,255,cv2.THRESH_OTSU)[1]\n",
    "    #Invert the image in case the objects of interest are in the dark side\n",
    "    if(np.sum(img_th==255)>np.sum(img_th==0)):\n",
    "        img_th=cv2.bitwise_not(img_th)\n",
    "    #second morphological opening (on binary image this time)\n",
    "    bin_open=cv2.morphologyEx(img_th, cv2.MORPH_OPEN, circle7) \n",
    "    #connected components\n",
    "    cc=cv2.connectedComponents(bin_open)[1]\n",
    "    #cc=segment_on_dt(bin_open,20)\n",
    "    return cc # convert to 1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cv2_masks[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_masks[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_cv2_masks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-f471ec6d357c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m# Plot a few random images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m#plot_check(train_images,train_masks,rand_imgs=3)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mplot_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_cv2_masks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_masks\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrand_imgs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;31m#plot_check(train_images,cv2_masks,rand_imgs=3)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_cv2_masks' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot images side by side for a list of datasets\n",
    "def plot_side_by_side(ds_list,image_num):\n",
    "    #print('Image #: ' + str(image_num) + '. Image Sizes: ' + str(image_ds[image_num].shape) + ' ' + str(mask_ds[image_num].shape))\n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "\n",
    "    for i in range(len(ds_list)):\n",
    "        ax1 = fig.add_subplot(1,len(ds_list),i+1)\n",
    "        ax1.imshow(ds_list[i][image_num])\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "# Plots random corresponding images and masks\n",
    "def plot_check(ds_list,rand_imgs=None,img_nums=None):\n",
    "    if rand_imgs != None:\n",
    "        for i in range(rand_imgs):\n",
    "            plot_side_by_side(ds_list, randint(0,len(ds_list[0])-1))\n",
    "    if img_nums != None:\n",
    "        for i in range(len(img_nums)):\n",
    "            plot_side_by_side(ds_list,img_nums[i])\n",
    "    \n",
    "#plot_side_by_side(train_images,train_mask_images,38)\n",
    "# Plot a few random images \n",
    "#plot_check(train_images,train_masks,rand_imgs=3)\n",
    "plot_check([train_images,train_cv2_masks,train_masks],rand_imgs=3)\n",
    "#plot_check(train_images,cv2_masks,rand_imgs=3)\n",
    "\n",
    "#plot_check(train_images,train_mask_images,img_nums=[309])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_cv2_masks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-9cc930e1f875>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mresized_train_masks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m \u001b[0mimg_as_bool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_width\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg_height\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_masks\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mresized_train_cv2_masks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m \u001b[0mimg_as_bool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_width\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg_height\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_cv2_masks\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#Croping\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_cv2_masks' is not defined"
     ]
    }
   ],
   "source": [
    "# Resize everything\n",
    "# Also do dtype conversions\n",
    "\n",
    "# Scaling\n",
    "resized_train_images = [ img_as_ubyte(resize(image,(img_width,img_height))) for image in train_images] \n",
    "\n",
    "resized_train_masks = [ img_as_bool(resize(image,(img_width,img_height))) for image in train_masks] \n",
    "resized_train_cv2_masks = [ img_as_bool(resize(image,(img_width,img_height))) for image in train_cv2_masks] \n",
    "\n",
    "#Croping\n",
    "\n",
    "#crop_size=64\n",
    "\n",
    "#resized_train_images = [ image[int(0.5*(image.shape[0]-crop_size)):int(0.5*(image.shape[0]+crop_size)),\n",
    "#   int(0.5*(image.shape[1]-crop_size)):int(0.5*(image.shape[1]+crop_size))] for image in train_images] \n",
    "\n",
    "#resized_train_mask_images = [ image[int(0.5*(image.shape[0]-crop_size)):int(0.5*(image.shape[0]+crop_size)),\n",
    "#   int(0.5*(image.shape[1]-crop_size)):int(0.5*(image.shape[1]+crop_size))] for image in train_mask_images] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check max pixel values\n",
    "print(resized_train_images[309].max())\n",
    "print(resized_train_images[16].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original image and mask\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_cv2_masks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-917aa4e3347b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Original image and mask'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mplot_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_cv2_masks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_masks\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg_nums\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m492\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Resized image and mask'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mplot_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mresized_train_images\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mresized_train_cv2_masks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mresized_train_masks\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg_nums\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m492\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_cv2_masks' is not defined"
     ]
    }
   ],
   "source": [
    "# Check to see that my resizing and compression is screwing stuff up\n",
    "rand_img_num = randint(0,len(train_images))\n",
    "#plot_check(compressed_train_images,compressed_train_masks,img_nums=[rand_img_num])\n",
    "#plot_check(train_images,train_mask_images,img_nums=[rand_img_num])\n",
    "\n",
    "print('Original image and mask')\n",
    "plot_check([train_images,train_cv2_masks,train_masks],img_nums=[492])\n",
    "print('Resized image and mask')\n",
    "plot_check([resized_train_images,resized_train_cv2_masks,resized_train_masks],img_nums=[492])\n",
    "\n",
    "#plot_check(train_images,train_mask_images,img_nums=[664])\n",
    "#print(train_images[664].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-82dd63801679>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Check to see that my resizing and compression is screwing stuff up\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrand_img_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m#plot_check(compressed_train_images,compressed_train_masks,img_nums=[rand_img_num])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#plot_check(train_images,train_mask_images,img_nums=[rand_img_num])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_images' is not defined"
     ]
    }
   ],
   "source": [
    "# Check to see that my resizing and compression is screwing stuff up\n",
    "rand_img_num = randint(0,len(train_images))\n",
    "#plot_check(compressed_train_images,compressed_train_masks,img_nums=[rand_img_num])\n",
    "#plot_check(train_images,train_mask_images,img_nums=[rand_img_num])\n",
    "\n",
    "print('Original image and mask')\n",
    "plot_check([train_images,train_masks],img_nums=[492])\n",
    "print('Resized image and mask')\n",
    "plot_check([resized_train_images,resized_train_masks],img_nums=[492])\n",
    "\n",
    "#plot_check(train_images,train_mask_images,img_nums=[664])\n",
    "#print(train_images[664].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(670, 128, 128, 1)\n",
      "(670, 128, 128, 1)\n",
      "10977280\n",
      "10977280\n"
     ]
    }
   ],
   "source": [
    "# Reshape model inputs\n",
    "train_X = np.reshape(np.array(resized_train_images),(len(resized_train_images),img_height,img_width,1))\n",
    "\n",
    "# Stack cv2 masks on top of images as a channel\n",
    "#train_X = np.reshape(np.stack((np.array(resized_train_images),np.array(resized_train_cv2_masks)),axis=3), \\\n",
    "#                     (len(resized_train_images),img_height,img_width,2))\n",
    "train_Y = np.reshape(np.array(resized_train_masks),(len(resized_train_masks),img_height,img_width,1))\n",
    "\n",
    "# Check size of arrays we are inputting to model\n",
    "# This is important! We need the datasets to be as \n",
    "# small as possible to reduce computation time\n",
    "print(train_X.shape)\n",
    "print(train_Y.shape)\n",
    "print(train_X.nbytes)\n",
    "print(train_Y.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bool\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "# Check datatypes\n",
    "print(train_Y.dtype)\n",
    "print(train_X.dtype)\n",
    "\n",
    "#train_X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_check([np.squeeze(train_X,axis=3),np.squeeze(train_Y,axis=3)],img_nums=[5,119])\n",
    "#plot_check([train_images,train_masks],img_nums=[5,119])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X[602].max() # check max pixel value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now Let's Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loss and metric functions for the neural net\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
    "    return score\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1. - score\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "def create_block(x, filters=21, filter_size=(3, 3), activation='relu',dil_rate=1,dropout_rate=0.2):\n",
    "#    for i in range(n_block):\n",
    "    x = Conv2D(filters, filter_size, padding='same', activation='relu', dilation_rate = dil_rate) (x)\n",
    "    #x = Activation('relu') (x)\n",
    "    x = BatchNormalization() (x) \n",
    "    x = Dropout(dropout_rate) (x)\n",
    "    return x\n",
    "\n",
    "\n",
    "## master function for creating a net\n",
    "def get_net(\n",
    "        input_shape=(img_height, img_width,1),\n",
    "        loss=binary_crossentropy,\n",
    "        n_class=1\n",
    "):\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    # Create layers\n",
    "    net_body = create_block(inputs)\n",
    "    net_body = create_block(net_body)\n",
    "    net_body = create_block(net_body)\n",
    "    net_body = create_block(net_body,dil_rate=2)\n",
    "    net_body = create_block(net_body,dil_rate=4)\n",
    "    net_body = create_block(net_body,dil_rate=8)\n",
    "    net_body = create_block(net_body)\n",
    "    classify = Conv2D(n_class,(1,1),activation='sigmoid') (net_body)\n",
    "    \n",
    "    #classify = Activation(activation='sigmoid') (net_body)\n",
    "    #classify = Dense(1,activation='sigmoid') (net_body)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=classify)\n",
    "    model.compile(optimizer=Adam(0.001), loss=loss, metrics=[bce_dice_loss, dice_coef])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_model = get_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 128, 128, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 128, 128, 21)      210       \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 128, 128, 21)      84        \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 128, 128, 21)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 128, 128, 21)      3990      \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 128, 128, 21)      84        \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 128, 128, 21)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 128, 128, 21)      3990      \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 128, 128, 21)      84        \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 128, 128, 21)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 128, 128, 21)      3990      \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 128, 128, 21)      84        \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 128, 128, 21)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 128, 128, 21)      3990      \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 128, 128, 21)      84        \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 128, 128, 21)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 128, 128, 21)      3990      \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 128, 128, 21)      84        \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 128, 128, 21)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 128, 128, 21)      3990      \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 128, 128, 21)      84        \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 128, 128, 21)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 128, 128, 1)       22        \n",
      "=================================================================\n",
      "Total params: 24,760\n",
      "Trainable params: 24,466\n",
      "Non-trainable params: 294\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(my_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 603 samples, validate on 67 samples\n",
      "Epoch 1/75\n",
      "600/603 [============================>.] - ETA: 1s - loss: 0.6506 - bce_dice_loss: 1.3553 - dice_coef: 0.3966\n",
      "Epoch 00001: val_loss improved from inf to 0.37011, saving model to meshnet_v2.h5\n",
      "603/603 [==============================] - 357s 592ms/step - loss: 0.6502 - bce_dice_loss: 1.3553 - dice_coef: 0.3963 - val_loss: 0.3701 - val_bce_dice_loss: 0.9163 - val_dice_coef: 0.6410\n",
      "Epoch 2/75\n",
      "600/603 [============================>.] - ETA: 1s - loss: 0.3764 - bce_dice_loss: 0.9238 - dice_coef: 0.6662\n",
      "Epoch 00002: val_loss improved from 0.37011 to 0.22300, saving model to meshnet_v2.h5\n",
      "603/603 [==============================] - 348s 578ms/step - loss: 0.3771 - bce_dice_loss: 0.9250 - dice_coef: 0.6650 - val_loss: 0.2230 - val_bce_dice_loss: 0.6370 - val_dice_coef: 0.7585\n",
      "Epoch 3/75\n",
      "600/603 [============================>.] - ETA: 1s - loss: 0.2554 - bce_dice_loss: 0.7045 - dice_coef: 0.7662\n",
      "Epoch 00003: val_loss improved from 0.22300 to 0.14688, saving model to meshnet_v2.h5\n",
      "603/603 [==============================] - 345s 572ms/step - loss: 0.2551 - bce_dice_loss: 0.7036 - dice_coef: 0.7664 - val_loss: 0.1469 - val_bce_dice_loss: 0.4269 - val_dice_coef: 0.8245\n",
      "Epoch 4/75\n",
      "600/603 [============================>.] - ETA: 1s - loss: 0.2090 - bce_dice_loss: 0.5993 - dice_coef: 0.7849\n",
      "Epoch 00004: val_loss improved from 0.14688 to 0.13989, saving model to meshnet_v2.h5\n",
      "603/603 [==============================] - 356s 591ms/step - loss: 0.2094 - bce_dice_loss: 0.6010 - dice_coef: 0.7835 - val_loss: 0.1399 - val_bce_dice_loss: 0.4070 - val_dice_coef: 0.8259\n",
      "Epoch 5/75\n",
      "600/603 [============================>.] - ETA: 1s - loss: 0.1691 - bce_dice_loss: 0.5036 - dice_coef: 0.8121\n",
      "Epoch 00005: val_loss improved from 0.13989 to 0.12198, saving model to meshnet_v2.h5\n",
      "603/603 [==============================] - 344s 570ms/step - loss: 0.1687 - bce_dice_loss: 0.5024 - dice_coef: 0.8126 - val_loss: 0.1220 - val_bce_dice_loss: 0.3562 - val_dice_coef: 0.8409\n",
      "Epoch 6/75\n",
      "600/603 [============================>.] - ETA: 1s - loss: 0.1525 - bce_dice_loss: 0.4529 - dice_coef: 0.8214\n",
      "Epoch 00006: val_loss improved from 0.12198 to 0.11603, saving model to meshnet_v2.h5\n",
      "603/603 [==============================] - 351s 583ms/step - loss: 0.1548 - bce_dice_loss: 0.4574 - dice_coef: 0.8186 - val_loss: 0.1160 - val_bce_dice_loss: 0.3430 - val_dice_coef: 0.8284\n",
      "Epoch 7/75\n",
      "600/603 [============================>.] - ETA: 1s - loss: 0.1413 - bce_dice_loss: 0.4261 - dice_coef: 0.8256\n",
      "Epoch 00007: val_loss did not improve\n",
      "603/603 [==============================] - 348s 577ms/step - loss: 0.1475 - bce_dice_loss: 0.4353 - dice_coef: 0.8220 - val_loss: 0.1250 - val_bce_dice_loss: 0.3656 - val_dice_coef: 0.8077\n",
      "Epoch 8/75\n",
      "600/603 [============================>.] - ETA: 1s - loss: 0.1379 - bce_dice_loss: 0.4157 - dice_coef: 0.8252\n",
      "Epoch 00008: val_loss did not improve\n",
      "603/603 [==============================] - 356s 590ms/step - loss: 0.1377 - bce_dice_loss: 0.4155 - dice_coef: 0.8252 - val_loss: 0.1191 - val_bce_dice_loss: 0.3420 - val_dice_coef: 0.8221\n",
      "Epoch 9/75\n",
      "600/603 [============================>.] - ETA: 1s - loss: 0.1233 - bce_dice_loss: 0.3691 - dice_coef: 0.8446\n",
      "Epoch 00009: val_loss improved from 0.11603 to 0.09931, saving model to meshnet_v2.h5\n",
      "603/603 [==============================] - 349s 579ms/step - loss: 0.1235 - bce_dice_loss: 0.3690 - dice_coef: 0.8445 - val_loss: 0.0993 - val_bce_dice_loss: 0.2923 - val_dice_coef: 0.8540\n",
      "Epoch 10/75\n",
      "600/603 [============================>.] - ETA: 1s - loss: 0.1200 - bce_dice_loss: 0.3599 - dice_coef: 0.8448\n",
      "Epoch 00010: val_loss did not improve\n",
      "603/603 [==============================] - 341s 565ms/step - loss: 0.1207 - bce_dice_loss: 0.3606 - dice_coef: 0.8444 - val_loss: 0.1108 - val_bce_dice_loss: 0.3194 - val_dice_coef: 0.8300\n",
      "Epoch 11/75\n",
      "600/603 [============================>.] - ETA: 1s - loss: 0.1220 - bce_dice_loss: 0.3613 - dice_coef: 0.8385\n",
      "Epoch 00011: val_loss improved from 0.09931 to 0.09858, saving model to meshnet_v2.h5\n",
      "603/603 [==============================] - 346s 574ms/step - loss: 0.1222 - bce_dice_loss: 0.3613 - dice_coef: 0.8384 - val_loss: 0.0986 - val_bce_dice_loss: 0.2974 - val_dice_coef: 0.8488\n",
      "Epoch 12/75\n",
      "200/603 [========>.....................] - ETA: 3:44 - loss: 0.1098 - bce_dice_loss: 0.3335 - dice_coef: 0.8523"
     ]
    }
   ],
   "source": [
    "# Fit model\n",
    "\n",
    "# learning rate decay https://keras.io/callbacks/#learningratescheduler \n",
    "\n",
    "# This function controls the learning rate based on the epoch\n",
    "# must return a float\n",
    "    \n",
    "#change_lr = LearningRateScheduler(scheduler,verbose=1)\n",
    "earlystopper = EarlyStopping(patience=10, verbose=1)\n",
    "checkpointer = ModelCheckpoint(model_checkpoint_file, verbose=1, save_best_only=True)\n",
    "reduce_plateau = ReduceLROnPlateau(monitor='val_loss', \n",
    "                           factor=0.5,\n",
    "                           patience=3,\n",
    "                           verbose=1,\n",
    "                        #   min_lr=0.00001,\n",
    "                            epsilon=0.001,\n",
    "                           mode='auto') \n",
    "# verbose=2 => one line per epoch, 1 = progress bar\n",
    "\n",
    "### Add an epsilon \n",
    "results = my_model.fit(train_X, train_Y, validation_split=0.1, batch_size=10, epochs=75, verbose=1, \n",
    "                       shuffle=True, callbacks=[ earlystopper, checkpointer, reduce_plateau])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Epoch 00013: LearningRateScheduler reducing learning rate to 0.0001.\n",
    "#Epoch 13/75\n",
    "#600/603 [============================>.] - ETA: 1s - loss: 0.2774 - dice_coef: 0.8625 - binary_crossentropy: 0.1149\n",
    "#Epoch 00013: val_loss improved from 0.25185 to 0.24854, saving model to bw_model_v8.h5\n",
    "#603/603 [==============================] - 221s 367ms/step - loss: 0.2768 - dice_coef: 0.8628 - binary_crossentropy: 0.1146 - val_loss: 0.2485 - val_dice_coef: 0.8691 - val_binary_crossentropy: 0.1000\n",
    "#Epoch 00017: LearningRateScheduler reducing learning rate to 0.0001.\n",
    "#Epoch 17/75\n",
    "#600/603 [============================>.] - ETA: 1s - loss: 0.2818 - dice_coef: 0.8604 - binary_crossentropy: 0.1164\n",
    "#Epoch 00017: val_loss did not improve\n",
    "#603/603 [==============================] - 217s 360ms/step - loss: 0.2842 - dice_coef: 0.8593 - binary_crossentropy: 0.1176 - val_loss: 0.2480 - val_dice_coef: 0.8686 - val_binary_crossentropy: 0.1002\n",
    "\n",
    "\n",
    "# Make predictions\n",
    "final_model = load_model(model_checkpoint_file, custom_objects={'dice_coef': dice_coef, 'bce_dice_loss':bce_dice_loss})\n",
    "#preds_train = final_model.predict(train_X[:int(train_X.shape[0]*0.9)], verbose=1)\n",
    "#preds_val = final_model.predict(train_X[int(train_X.shape[0]*0.9):], verbose=1)\n",
    "\n",
    "preds_train = final_model.predict(train_X, verbose=1)\n",
    "\n",
    "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
    "#preds_val_t = (preds_val > 0.5).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ideas\n",
    " - Experiment with compression of training data. Am I preserving as much detail\n",
    "    as I can in dtype np.uint8 (values of 0 to 255) ?\n",
    "- Color vs B&W?\n",
    "- Combine mask and prediction images to show false positives and negatives\n",
    "- What is the best resizing method? Reflect??\n",
    "- Put computer vision / threshold method output as an input to neural net\n",
    "- Output intermediate layers for inspection\n",
    "- Crop images to train networks faster for testing ??\n",
    "- Take random crops of images to create, and then combine outputs in the end\n",
    "- Is combining the masks really the best thing to do? Should I be keeping the individual cells separate?\n",
    "- Pseudo-labelled data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
